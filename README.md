# SEO-1st-page-Google-data-scrape

This project is a powerful and efficient SEO scraping tool that scrapes data from the first page of Google search results for a list of keywords. It is built using Python, Selenium, and PySimpleGUI, and allows you to customize proxy settings and user agent to ensure a smooth scraping experience.

The scraped data includes the website's URL, H1, H2, and H3 tags, meta content, and meta description. The data is then saved in a CSV file for further analysis and processing.

## :sparkles: Features

- Scrape data from the first page of Google search results
- Customize proxy settings and user agent
- Save scraped data in a CSV file
- Efficient and user-friendly GUI

## :hammer_and_wrench: Installation

1. Install Python 3.7+ if not already installed.

2. Clone the repository:

   ```
   git clone https://github.com/andreireporter13/SEO-1st-page-Google-data-scrape.git
   ```

3. Change to the project directory:

   ```
   cd SEO-1st-page-Google-data-scrape
   ```

4. Install the required dependencies:

   ```
   pip install -r requirements.txt
   ```

5. Run the script:

   ```
   python main.py
   ```

## :computer: Usage

1. Enter the keywords (up to 3) separated by commas in the input field.
2. Click on "Run Scraper" to begin scraping data from the first page of Google search results.
3. The progress bar will show the progress of the scraping process.
4. Once the scraping is complete, a CSV file with the scraped data will be saved in the project directory.
5. You can customize the proxy settings and user agent from the menu options.

## :memo: License

This project is licensed under the MIT License.

## :email: Contact

Feel free to reach out to the authors:

- Andrei C. Cojocaru: [LinkedIn](https://www.linkedin.com/in/andrei-c-cojocaru)
- Baluta Laurentiu Marian: [LinkedIn](https://www.linkedin.com/in/baluta-laurentiu-marian)

For more information about our work, visit our website: [https://webautomation.ro](https://webautomation.ro)
